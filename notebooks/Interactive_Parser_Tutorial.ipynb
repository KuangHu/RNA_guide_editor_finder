{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNA Guide Editor Finder - Interactive Parser Tutorial\n",
    "\n",
    "This notebook demonstrates all parser functions with interactive examples.\n",
    "You can run each cell to see inputs and outputs.\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary modules\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import tempfile\n",
    "\n",
    "# Add project to path\n",
    "project_root = Path.cwd()\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Import parsers\n",
    "from utils.parsers import (\n",
    "    # Prodigal parsers\n",
    "    parse_prodigal_faa,\n",
    "    parse_prodigal_faa_full,\n",
    "    # FASTA parsers\n",
    "    parse_fasta,\n",
    "    parse_fasta_records,\n",
    "    # Diamond BLASTP parsers\n",
    "    parse_diamond_blastp,\n",
    "    parse_diamond_blastp_with_positions,\n",
    "    # HMMER parsers\n",
    "    parse_hmm_tblout,\n",
    "    parse_hmm_tblout_with_positions,\n",
    "    # Sequence retrieval\n",
    "    retrieve_sequence_from_fasta,\n",
    "    retrieve_sequences_from_hits,\n",
    "    reverse_complement,\n",
    "    # DataFrame conversion\n",
    "    diamond_hits_to_dataframe,\n",
    "    hmm_hits_to_dataframe,\n",
    "    save_hits_to_csv,\n",
    ")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "print(\"✓ All modules imported successfully!\")\n",
    "print(f\"Working directory: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Sample Data Files\n",
    "\n",
    "Let's create sample files to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary directory for sample files\n",
    "temp_dir = Path(tempfile.mkdtemp(prefix='parser_tutorial_'))\n",
    "print(f\"Created temporary directory: {temp_dir}\")\n",
    "\n",
    "# 1. Create sample FASTA file\n",
    "fasta_file = temp_dir / \"sample_genome.fna\"\n",
    "fasta_content = \"\"\">contig_1\n",
    "ATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCG\n",
    "GCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTA\n",
    "TACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTACG\n",
    "CGTAGCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGA\n",
    ">contig_2\n",
    "AAAATTTTCCCCGGGGAAAATTTTCCCCGGGGAAAATTTTCCCCGGGGAAAATTTTCCCC\n",
    "GGGGAAAATTTTCCCCGGGGAAAATTTTCCCCGGGGAAAATTTTCCCCGGGGAAAATTTT\n",
    "\"\"\"\n",
    "fasta_file.write_text(fasta_content)\n",
    "print(f\"✓ Created: {fasta_file.name}\")\n",
    "\n",
    "# 2. Create sample Prodigal FAA file\n",
    "prodigal_faa = temp_dir / \"proteins.faa\"\n",
    "prodigal_content = \"\"\">contig_1_1 # 100 # 300 # 1 # ID=1_1;partial=00;start_type=ATG;rbs_motif=None\n",
    "MKLVPQRSTAVILGKLMNPQRSTAVILGKLMNPQ\n",
    ">contig_1_2 # 500 # 800 # -1 # ID=1_2;partial=00;start_type=ATG;rbs_motif=GGA\n",
    "MLKIPVRSTQAVILGKLMNPQRSTAVILGKLMN\n",
    ">contig_2_1 # 50 # 250 # 1 # ID=2_1;partial=00;start_type=ATG;rbs_motif=None\n",
    "MKLVPQRSTAVILGKLMNPQRSTAVILGKLMNPQRST\n",
    "\"\"\"\n",
    "prodigal_faa.write_text(prodigal_content)\n",
    "print(f\"✓ Created: {prodigal_faa.name}\")\n",
    "\n",
    "# 3. Create sample Diamond BLASTP results\n",
    "diamond_file = temp_dir / \"diamond_results.m8\"\n",
    "diamond_content = \"\"\"contig_1_1\\tIS110_transposase\\t95.5\\t200\\t9\\t0\\t1\\t200\\t15\\t214\\t1.0e-100\\t350.5\n",
    "contig_1_2\\tIS110_orfB\\t88.2\\t150\\t18\\t1\\t1\\t150\\t10\\t159\\t2.3e-75\\t280.3\n",
    "contig_2_1\\tDNA_polymerase\\t92.0\\t180\\t14\\t0\\t1\\t180\\t5\\t184\\t5.1e-90\\t320.1\n",
    "\"\"\"\n",
    "diamond_file.write_text(diamond_content)\n",
    "print(f\"✓ Created: {diamond_file.name}\")\n",
    "\n",
    "# 4. Create sample HMMER tblout results\n",
    "hmmer_file = temp_dir / \"hmmer_results.tbl\"\n",
    "hmmer_content = \"\"\"# target name        accession   tlen query name           accession   qlen   E-value  score  bias   #  of  c-Evalue  i-Evalue  score  bias  from    to  from    to  from    to  acc description\n",
    "contig_1_1           -            200 IS110_transposase    PF03400.15   250  1.5e-100  350.5   0.1   1   1  1.5e-100  1.5e-100  350.5   0.1     1   250     1   200     1   200 0.98 -\n",
    "contig_1_2           -            150 IS110_orfB           PF12345.10   180  2.3e-75   280.3   0.2   1   1  2.3e-75   2.3e-75   280.3   0.2     1   180     1   150     1   150 0.95 -\n",
    "contig_2_1           -            180 DNA_polymerase       PF00136.22   200  5.1e-90   320.1   0.0   1   1  5.1e-90   5.1e-90   320.1   0.0     1   200     1   180     1   180 0.99 -\n",
    "\"\"\"\n",
    "hmmer_file.write_text(hmmer_content)\n",
    "print(f\"✓ Created: {hmmer_file.name}\")\n",
    "\n",
    "print(\"\\n✓ All sample files created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 1: Prodigal Parsers\n",
    "\n",
    "Parse Prodigal output to get protein positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the input file\n",
    "print(\"INPUT FILE (proteins.faa):\")\n",
    "print(\"=\" * 70)\n",
    "print(prodigal_faa.read_text())\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse positions only\n",
    "print(\"FUNCTION: parse_prodigal_faa()\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "position_map = parse_prodigal_faa(str(prodigal_faa))\n",
    "\n",
    "print(\"\\nOUTPUT (position_map):\")\n",
    "print(f\"Type: {type(position_map)}\")\n",
    "print(f\"Number of proteins: {len(position_map)}\")\n",
    "print(\"\\nContents:\")\n",
    "for protein_id, (start, end, strand) in position_map.items():\n",
    "    strand_str = \"forward\" if strand == 1 else \"reverse\"\n",
    "    print(f\"  {protein_id}: {start}..{end} ({strand_str})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse full information including sequences\n",
    "print(\"FUNCTION: parse_prodigal_faa_full()\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "genes = parse_prodigal_faa_full(str(prodigal_faa))\n",
    "\n",
    "print(\"\\nOUTPUT (genes):\")\n",
    "print(f\"Type: {type(genes)}\")\n",
    "print(f\"Number of genes: {len(genes)}\")\n",
    "\n",
    "print(\"\\nFirst gene details:\")\n",
    "first_gene = genes['contig_1_1']\n",
    "print(f\"  protein_id: {first_gene.protein_id}\")\n",
    "print(f\"  start: {first_gene.start}\")\n",
    "print(f\"  end: {first_gene.end}\")\n",
    "print(f\"  strand: {first_gene.strand}\")\n",
    "print(f\"  length: {first_gene.length}\")\n",
    "print(f\"  is_forward: {first_gene.is_forward}\")\n",
    "print(f\"  sequence: {first_gene.sequence[:30]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 2: FASTA Parsers\n",
    "\n",
    "Parse FASTA files to get genomic sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the input file\n",
    "print(\"INPUT FILE (sample_genome.fna):\")\n",
    "print(\"=\" * 70)\n",
    "print(fasta_file.read_text())\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse as dictionary\n",
    "print(\"FUNCTION: parse_fasta()\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "sequences = parse_fasta(str(fasta_file))\n",
    "\n",
    "print(\"\\nOUTPUT (sequences):\")\n",
    "print(f\"Type: {type(sequences)}\")\n",
    "print(f\"Number of sequences: {len(sequences)}\")\n",
    "\n",
    "for seq_id, sequence in sequences.items():\n",
    "    print(f\"\\n  {seq_id}:\")\n",
    "    print(f\"    Length: {len(sequence)} bp\")\n",
    "    print(f\"    First 60 bp: {sequence[:60]}\")\n",
    "    print(f\"    Last 60 bp: {sequence[-60:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse as records\n",
    "print(\"FUNCTION: parse_fasta_records()\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "records = parse_fasta_records(str(fasta_file))\n",
    "\n",
    "print(\"\\nOUTPUT (records):\")\n",
    "print(f\"Type: {type(records)}\")\n",
    "print(f\"Number of records: {len(records)}\")\n",
    "\n",
    "for record in records:\n",
    "    print(f\"\\n  Record:\")\n",
    "    print(f\"    ID: {record.id}\")\n",
    "    print(f\"    Header: {record.header}\")\n",
    "    print(f\"    Length: {record.length} bp\")\n",
    "    print(f\"    Sequence: {record.sequence[:60]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 3: Diamond BLASTP Parsers\n",
    "\n",
    "Parse Diamond BLASTP results with genomic positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the input files\n",
    "print(\"INPUT FILE 1 (diamond_results.m8):\")\n",
    "print(\"=\" * 70)\n",
    "print(diamond_file.read_text())\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nINPUT 2 (position_map from Prodigal):\")\n",
    "print(\"=\" * 70)\n",
    "for protein_id, (start, end, strand) in position_map.items():\n",
    "    print(f\"  {protein_id}: ({start}, {end}, {strand})\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse basic Diamond results (without positions)\n",
    "print(\"FUNCTION: parse_diamond_blastp()\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "basic_hits = parse_diamond_blastp(str(diamond_file))\n",
    "\n",
    "print(\"\\nOUTPUT (basic_hits):\")\n",
    "print(f\"Type: {type(basic_hits)}\")\n",
    "print(f\"Number of hits: {len(basic_hits)}\")\n",
    "\n",
    "print(\"\\nFirst hit (tuple):\")\n",
    "print(f\"  {basic_hits[0]}\")\n",
    "\n",
    "print(\"\\nParsed fields:\")\n",
    "hit = basic_hits[0]\n",
    "print(f\"  query_id: {hit[0]}\")\n",
    "print(f\"  subject_id: {hit[1]}\")\n",
    "print(f\"  pident: {hit[2]}%\")\n",
    "print(f\"  alignment_length: {hit[3]}\")\n",
    "print(f\"  evalue: {hit[10]}\")\n",
    "print(f\"  bitscore: {hit[11]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse Diamond results WITH positions\n",
    "print(\"FUNCTION: parse_diamond_blastp_with_positions()\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "hits = parse_diamond_blastp_with_positions(\n",
    "    str(diamond_file),\n",
    "    position_map,\n",
    "    file_basename=\"sample_genome\"\n",
    ")\n",
    "\n",
    "print(\"\\nOUTPUT (hits):\")\n",
    "print(f\"Type: {type(hits)}\")\n",
    "print(f\"Number of hits: {len(hits)}\")\n",
    "\n",
    "print(\"\\nFirst hit (DiamondBlastHit object):\")\n",
    "hit = hits[0]\n",
    "print(f\"  file_basename: {hit.file_basename}\")\n",
    "print(f\"  contig_id: {hit.contig_id}\")\n",
    "print(f\"  protein_id: {hit.protein_id}\")\n",
    "print(f\"  start: {hit.start}\")\n",
    "print(f\"  end: {hit.end}\")\n",
    "print(f\"  strand: {hit.strand}\")\n",
    "print(f\"  is_forward: {hit.is_forward}\")\n",
    "print(f\"  length: {hit.length} bp\")\n",
    "print(f\"  query_id: {hit.query_id}\")\n",
    "print(f\"  subject_id: {hit.subject_id}\")\n",
    "print(f\"  pident: {hit.pident}%\")\n",
    "print(f\"  evalue: {hit.evalue}\")\n",
    "print(f\"  bitscore: {hit.bitscore}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 4: HMMER Parsers\n",
    "\n",
    "Parse HMMER tblout results with genomic positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the input file\n",
    "print(\"INPUT FILE (hmmer_results.tbl):\")\n",
    "print(\"=\" * 70)\n",
    "print(hmmer_file.read_text())\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse basic HMMER results\n",
    "print(\"FUNCTION: parse_hmm_tblout()\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "basic_hmm_hits = parse_hmm_tblout(str(hmmer_file))\n",
    "\n",
    "print(\"\\nOUTPUT (basic_hmm_hits):\")\n",
    "print(f\"Type: {type(basic_hmm_hits)}\")\n",
    "print(f\"Number of hits: {len(basic_hmm_hits)}\")\n",
    "\n",
    "print(\"\\nFirst hit (tuple):\")\n",
    "hit = basic_hmm_hits[0]\n",
    "print(f\"  target_name: {hit[0]}\")\n",
    "print(f\"  query_name: {hit[1]}\")\n",
    "print(f\"  accession: {hit[2]}\")\n",
    "print(f\"  evalue: {hit[3]}\")\n",
    "print(f\"  score: {hit[4]}\")\n",
    "print(f\"  bias: {hit[5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse HMMER results WITH positions\n",
    "print(\"FUNCTION: parse_hmm_tblout_with_positions()\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "hmm_hits = parse_hmm_tblout_with_positions(\n",
    "    str(hmmer_file),\n",
    "    position_map,\n",
    "    file_basename=\"sample_genome\"\n",
    ")\n",
    "\n",
    "print(\"\\nOUTPUT (hmm_hits):\")\n",
    "print(f\"Type: {type(hmm_hits)}\")\n",
    "print(f\"Number of hits: {len(hmm_hits)}\")\n",
    "\n",
    "print(\"\\nFirst hit (HmmHit object):\")\n",
    "hit = hmm_hits[0]\n",
    "print(f\"  file_basename: {hit.file_basename}\")\n",
    "print(f\"  contig_id: {hit.contig_id}\")\n",
    "print(f\"  protein_id: {hit.protein_id}\")\n",
    "print(f\"  start: {hit.start}\")\n",
    "print(f\"  end: {hit.end}\")\n",
    "print(f\"  strand: {hit.strand}\")\n",
    "print(f\"  is_forward: {hit.is_forward}\")\n",
    "print(f\"  length: {hit.length} bp\")\n",
    "print(f\"  query_name: {hit.query_name}\")\n",
    "print(f\"  target_name: {hit.target_name}\")\n",
    "print(f\"  evalue: {hit.evalue}\")\n",
    "print(f\"  score: {hit.score}\")\n",
    "print(f\"  bias: {hit.bias}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 5: Sequence Retrieval\n",
    "\n",
    "Retrieve actual genomic sequences from FASTA files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test reverse complement\n",
    "print(\"FUNCTION: reverse_complement()\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "test_seq = \"ATCGATCG\"\n",
    "rev_comp = reverse_complement(test_seq)\n",
    "\n",
    "print(f\"\\nINPUT:  {test_seq}\")\n",
    "print(f\"OUTPUT: {rev_comp}\")\n",
    "\n",
    "test_seq2 = \"AAAATTTTCCCCGGGG\"\n",
    "rev_comp2 = reverse_complement(test_seq2)\n",
    "\n",
    "print(f\"\\nINPUT:  {test_seq2}\")\n",
    "print(f\"OUTPUT: {rev_comp2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve a specific sequence\n",
    "print(\"FUNCTION: retrieve_sequence_from_fasta()\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nINPUT:\")\n",
    "print(f\"  FASTA file: {fasta_file.name}\")\n",
    "print(f\"  contig_id: contig_1\")\n",
    "print(f\"  start: 1\")\n",
    "print(f\"  end: 30\")\n",
    "print(f\"  strand: 1 (forward)\")\n",
    "\n",
    "seq_forward = retrieve_sequence_from_fasta(\n",
    "    str(fasta_file),\n",
    "    contig_id=\"contig_1\",\n",
    "    start=1,\n",
    "    end=30,\n",
    "    strand=1\n",
    ")\n",
    "\n",
    "print(f\"\\nOUTPUT (forward):\")\n",
    "print(f\"  {seq_forward}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"\\nINPUT (reverse strand):\")\n",
    "print(f\"  strand: -1 (reverse)\")\n",
    "\n",
    "seq_reverse = retrieve_sequence_from_fasta(\n",
    "    str(fasta_file),\n",
    "    contig_id=\"contig_1\",\n",
    "    start=1,\n",
    "    end=30,\n",
    "    strand=-1\n",
    ")\n",
    "\n",
    "print(f\"\\nOUTPUT (reverse - automatically reverse complemented):\")\n",
    "print(f\"  {seq_reverse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve sequences for all Diamond hits\n",
    "print(\"FUNCTION: retrieve_sequences_from_hits()\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nINPUT:\")\n",
    "print(f\"  Number of hits: {len(hits)}\")\n",
    "print(f\"  FASTA files: [{fasta_file.name}]\")\n",
    "\n",
    "# Before retrieval\n",
    "print(\"\\nBEFORE retrieval:\")\n",
    "for i, hit in enumerate(hits):\n",
    "    has_seq = hasattr(hit, 'genomic_sequence') and hit.genomic_sequence\n",
    "    print(f\"  Hit {i+1}: has_sequence = {has_seq}\")\n",
    "\n",
    "# Retrieve sequences\n",
    "hits_with_seq = retrieve_sequences_from_hits(\n",
    "    hits,\n",
    "    [str(fasta_file)],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\nAFTER retrieval:\")\n",
    "for i, hit in enumerate(hits_with_seq):\n",
    "    has_seq = hasattr(hit, 'genomic_sequence') and hit.genomic_sequence\n",
    "    if has_seq:\n",
    "        seq_len = len(hit.genomic_sequence)\n",
    "        seq_preview = hit.genomic_sequence[:40] if len(hit.genomic_sequence) > 40 else hit.genomic_sequence\n",
    "        print(f\"  Hit {i+1}:\")\n",
    "        print(f\"    protein_id: {hit.protein_id}\")\n",
    "        print(f\"    position: {hit.contig_id}:{hit.start}-{hit.end}\")\n",
    "        print(f\"    strand: {'forward' if hit.is_forward else 'reverse'}\")\n",
    "        print(f\"    sequence_length: {seq_len} bp\")\n",
    "        print(f\"    sequence: {seq_preview}...\")\n",
    "    else:\n",
    "        print(f\"  Hit {i+1}: NO SEQUENCE (contig not found)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 6: DataFrame Conversion\n",
    "\n",
    "Convert hits to pandas DataFrames for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Diamond hits to DataFrame\n",
    "print(\"FUNCTION: diamond_hits_to_dataframe()\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nINPUT:\")\n",
    "print(f\"  Number of hits: {len(hits_with_seq)}\")\n",
    "print(f\"  Type: List[DiamondBlastHit]\")\n",
    "\n",
    "df_diamond = diamond_hits_to_dataframe(hits_with_seq)\n",
    "\n",
    "print(\"\\nOUTPUT:\")\n",
    "print(f\"  Type: {type(df_diamond)}\")\n",
    "print(f\"  Shape: {df_diamond.shape}\")\n",
    "print(f\"  Columns: {df_diamond.columns.tolist()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"DataFrame content:\")\n",
    "print(\"=\" * 70)\n",
    "df_diamond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show specific columns\n",
    "print(\"Selected columns from DataFrame:\")\n",
    "print(\"=\" * 70)\n",
    "df_diamond[['protein_id', 'subject_id', 'pident', 'evalue', 'bitscore', 'is_forward']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame info\n",
    "print(\"DataFrame info:\")\n",
    "print(\"=\" * 70)\n",
    "df_diamond.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert HMMER hits to DataFrame\n",
    "print(\"FUNCTION: hmm_hits_to_dataframe()\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "df_hmmer = hmm_hits_to_dataframe(hmm_hits)\n",
    "\n",
    "print(\"\\nOUTPUT:\")\n",
    "print(f\"  Type: {type(df_hmmer)}\")\n",
    "print(f\"  Shape: {df_hmmer.shape}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"DataFrame content:\")\n",
    "print(\"=\" * 70)\n",
    "df_hmmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 7: DataFrame Analysis Examples\n",
    "\n",
    "Practical examples of analyzing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by E-value\n",
    "print(\"FILTER: E-value < 1e-80\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "high_confidence = df_diamond[df_diamond['evalue'] < 1e-80]\n",
    "\n",
    "print(f\"\\nOriginal hits: {len(df_diamond)}\")\n",
    "print(f\"Filtered hits: {len(high_confidence)}\")\n",
    "print(\"\\nFiltered results:\")\n",
    "high_confidence[['protein_id', 'subject_id', 'evalue', 'pident']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by identity\n",
    "print(\"FILTER: Identity > 90%\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "high_identity = df_diamond[df_diamond['pident'] > 90]\n",
    "\n",
    "print(f\"\\nHits with >90% identity: {len(high_identity)}\")\n",
    "high_identity[['protein_id', 'subject_id', 'pident', 'evalue']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex filtering (multiple conditions)\n",
    "print(\"FILTER: E-value < 1e-80 AND Identity > 90% AND Forward strand\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "filtered = df_diamond[\n",
    "    (df_diamond['evalue'] < 1e-80) &\n",
    "    (df_diamond['pident'] > 90) &\n",
    "    (df_diamond['is_forward'])\n",
    "]\n",
    "\n",
    "print(f\"\\nFiltered hits: {len(filtered)}\")\n",
    "filtered[['protein_id', 'subject_id', 'pident', 'evalue', 'is_forward']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by E-value\n",
    "print(\"SORT: By E-value (ascending)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "sorted_df = df_diamond.sort_values('evalue')\n",
    "sorted_df[['protein_id', 'subject_id', 'evalue', 'bitscore']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by subject\n",
    "print(\"GROUP BY: subject_id\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "by_subject = df_diamond.groupby('subject_id').agg({\n",
    "    'protein_id': 'count',\n",
    "    'pident': 'mean',\n",
    "    'evalue': 'min',\n",
    "    'bitscore': 'max'\n",
    "})\n",
    "by_subject.columns = ['count', 'mean_pident', 'min_evalue', 'max_bitscore']\n",
    "\n",
    "print(\"\\nResults:\")\n",
    "by_subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics\n",
    "print(\"STATISTICS: Summary statistics\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nNumeric columns:\")\n",
    "df_diamond[['pident', 'evalue', 'bitscore', 'length']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count by category\n",
    "print(\"VALUE COUNTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nHits per subject:\")\n",
    "print(df_diamond['subject_id'].value_counts())\n",
    "\n",
    "print(\"\\nHits per strand:\")\n",
    "print(df_diamond['is_forward'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 8: Export Results\n",
    "\n",
    "Save results to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV\n",
    "print(\"EXPORT: Save to CSV\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "csv_file = temp_dir / \"diamond_results.csv\"\n",
    "\n",
    "df_diamond.to_csv(csv_file, index=False)\n",
    "\n",
    "print(f\"\\n✓ Saved to: {csv_file}\")\n",
    "print(f\"  File size: {csv_file.stat().st_size} bytes\")\n",
    "print(f\"  Rows: {len(df_diamond)}\")\n",
    "print(f\"  Columns: {len(df_diamond.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read it back\n",
    "print(\"READ: Load CSV file\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "df_loaded = pd.read_csv(csv_file)\n",
    "\n",
    "print(f\"\\nLoaded DataFrame:\")\n",
    "print(f\"  Shape: {df_loaded.shape}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "df_loaded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use built-in save function\n",
    "print(\"FUNCTION: save_hits_to_csv()\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "csv_file2 = temp_dir / \"diamond_results_v2.csv\"\n",
    "\n",
    "save_hits_to_csv(hits_with_seq, str(csv_file2), include_sequence=True)\n",
    "\n",
    "print(f\"\\n✓ File created: {csv_file2.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 9: Complete Workflow Example\n",
    "\n",
    "Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"COMPLETE WORKFLOW\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Step 1: Parse Prodigal\n",
    "print(\"\\nStep 1: Parse Prodigal FAA\")\n",
    "position_map = parse_prodigal_faa(str(prodigal_faa))\n",
    "print(f\"  ✓ Found {len(position_map)} proteins\")\n",
    "\n",
    "# Step 2: Parse Diamond BLASTP\n",
    "print(\"\\nStep 2: Parse Diamond BLASTP with positions\")\n",
    "hits = parse_diamond_blastp_with_positions(\n",
    "    str(diamond_file),\n",
    "    position_map,\n",
    "    file_basename=\"sample_genome\"\n",
    ")\n",
    "print(f\"  ✓ Found {len(hits)} hits\")\n",
    "\n",
    "# Step 3: Retrieve sequences\n",
    "print(\"\\nStep 3: Retrieve genomic sequences\")\n",
    "hits = retrieve_sequences_from_hits(hits, [str(fasta_file)], verbose=False)\n",
    "with_seq = sum(1 for h in hits if hasattr(h, 'genomic_sequence') and h.genomic_sequence)\n",
    "print(f\"  ✓ Retrieved sequences for {with_seq}/{len(hits)} hits\")\n",
    "\n",
    "# Step 4: Convert to DataFrame\n",
    "print(\"\\nStep 4: Convert to DataFrame\")\n",
    "df = diamond_hits_to_dataframe(hits)\n",
    "print(f\"  ✓ Created DataFrame with shape {df.shape}\")\n",
    "\n",
    "# Step 5: Filter\n",
    "print(\"\\nStep 5: Filter high-confidence hits\")\n",
    "high_conf = df[(df['evalue'] < 1e-80) & (df['pident'] > 90)]\n",
    "print(f\"  ✓ {len(high_conf)} hits pass filter\")\n",
    "\n",
    "# Step 6: Analyze\n",
    "print(\"\\nStep 6: Group by subject\")\n",
    "summary = df.groupby('subject_id')['pident'].mean()\n",
    "print(\"  ✓ Summary statistics:\")\n",
    "for subject, mean_id in summary.items():\n",
    "    print(f\"    {subject}: {mean_id:.1f}% mean identity\")\n",
    "\n",
    "# Step 7: Export\n",
    "print(\"\\nStep 7: Export results\")\n",
    "output_file = temp_dir / \"final_results.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"  ✓ Saved to {output_file.name}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"✓ WORKFLOW COMPLETE!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Summary\n",
    "\n",
    "You've now seen all the major functions in action:\n",
    "\n",
    "1. **Prodigal Parsers** - Get protein positions\n",
    "2. **FASTA Parsers** - Get genomic sequences\n",
    "3. **Diamond BLASTP Parsers** - Parse BLAST results with positions\n",
    "4. **HMMER Parsers** - Parse HMM results with positions\n",
    "5. **Sequence Retrieval** - Get actual DNA sequences\n",
    "6. **DataFrame Conversion** - Convert to pandas for analysis\n",
    "7. **Analysis** - Filter, sort, group, aggregate\n",
    "8. **Export** - Save results to CSV/Excel\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Modify the examples with your own data\n",
    "- Try different filters and analyses\n",
    "- Combine multiple genomes\n",
    "- Create visualizations with matplotlib/seaborn\n",
    "\n",
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up temporary files\n",
    "import shutil\n",
    "\n",
    "print(f\"Temporary directory: {temp_dir}\")\n",
    "print(f\"Files created: {len(list(temp_dir.glob('*')))}\")\n",
    "\n",
    "# Uncomment to delete\n",
    "# shutil.rmtree(temp_dir)\n",
    "# print(\"✓ Temporary files cleaned up\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
